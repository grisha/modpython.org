<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [mod_python] ValueError: Failed to acquire global mutex lock
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:mod_python%40modpython.org?Subject=%5Bmod_python%5D%20ValueError%3A%20Failed%20to%20acquire%20global%20mutex%20lock&In-Reply-To=">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="025520.html">
   <LINK REL="Next"  HREF="025523.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[mod_python] ValueError: Failed to acquire global mutex lock</H1>
<table border=0 width="100%"><tr><td valign="top">
    <B>David Cardozo</B> 
    <A HREF="mailto:mod_python%40modpython.org?Subject=%5Bmod_python%5D%20ValueError%3A%20Failed%20to%20acquire%20global%20mutex%20lock&In-Reply-To="
       TITLE="[mod_python] ValueError: Failed to acquire global mutex lock">david.cardozo at apioutsourcing.com
       </A><BR>
    <I>Wed Aug  6 11:18:43 EDT 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="025520.html">[mod_python] PyODBC makes me crazy... Is mxODBC working good?
</A></li>
        <LI>Next message: <A HREF="025523.html">[mod_python] ValueError: Failed to acquire global mutex lock
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#25521">[ date ]</a>
              <a href="thread.html#25521">[ thread ]</a>
              <a href="subject.html#25521">[ subject ]</a>
              <a href="author.html#25521">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I apologize by resurrecting this email thread, but I thought I would post
the &#179;what worked for me&#178; solution in case someone else ever come across it.

For a quick history: when Mike Robokoff worked on this issue back in October
(we both worked together at the same company), we were able to work around
it by making changes to our python scripts to minimize the time spent
holding a lock to the Session.dbm file. This seemed to work fine for a
while. However, as our user load level increased, this problem started
manifesting itself again. I dedicated myself to this issue during this past
week and finally was able to narrow it down to the fix that solve it...
Hopefully once and for all.

Here is my analysis of this issue; please correct me if you think something
doesn&#185;t sound right:

The root cause of this problem was the use of a bad mutex implementation by
mod_python in Solaris.

Mod_python relies on operating system mutexes to lock file system resources;
these mutexes are provided by the APR library (Apache Portable Runtime) by
invocation of the following method from mod_python.c:

 apr_global_mutex_create(&amp;mutex[n], fname, APR_LOCK_DEFAULT, p);

The above call defaults to use the operating system default mutex
implementation (fcntl) which, in my opinion, does not work properly in an
Apache worker MPM model under any type of load.

by modifying the above call to:

apr_global_mutex_create(&amp;mutex[n], fname,  APR_LOCK_POSIXSEM, p);

which forces the use of the POSIX semaphores implementation of mutexes by
mod_python, the problem was minimized to a just a few instances of the
&quot;mutex&quot; error under a moderate load: 400 concurrent threads.

The final change to make the problem go away completely was to modify the
AcceptMutex and SSLMutex properties in the httpd.conf file to &quot;posixsem&quot;.
This, together with the mod_python changed, made the &quot;mutex&quot; error go away
even for 6400 concurrent threads.

I still ignore why the changes to AcceptMutex and SSLMutex are required
since our Apache installs were compiled with the
&quot;--enable-nonportable-atomics&quot; which, according to the Apache documentation
( <A HREF="http://httpd.apache.org/docs/2.2/misc/perf-tuning.html#compiletime">http://httpd.apache.org/docs/2.2/misc/perf-tuning.html#compiletime</A>):

&quot;Solaris on SPARC
By default, APR uses mutex-based atomics on Solaris/SPARC. If you configure
with --enable-nonportable-atomics, however, APR generates code that uses a
SPARC v8plus opcode for fast hardware compare-and-swap. If you configure
Apache with this option, the atomic operations will be more efficient
(allowing for lower CPU utilization and higher concurrency), but the
resulting executable will run only on UltraSPARC chips. &quot;

Maybe, even though we compile with that option, something in the OS, Apache
or APR, still doesn't allow us to take advantage of atomic operations. This
is pure speculation.

This is the email thread that pointed me to the right direction:
<A HREF="http://www.modpython.org/pipermail/mod_python/2006-November/022538.html">http://www.modpython.org/pipermail/mod_python/2006-November/022538.html</A>
I&#185;m not using the ITK MPM, just straight worker MPM, but that change made
the trick for me.

Regards,

David.

-------------- Last message in email thread ---------------------------

[mod_python] ValueError: Failed to acquire global mutex lock
Graham Dumpleton graham.dumpleton at gmail.com
Wed Oct 24 23:04:05 EDT 2007

    * Previous message: [mod_python] Problems with Apache
    * Next message: [mod_python] Multiple Django Applications
    * Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]

Going by errors posted by someone else for other thread, seems that if
semaphores exhausted, error would occur at mod_python startup not when
locking the mutex.

I'll have to go back and read all your emails again. You said you were
using 'worker' MPM now didn't you. Your not using some strange MPM
like perchild or ITK-MPM are you. I know that these cause problems for
these mutexes in mod_python because of how different processes wanting
to lock the mutex run as different users.

Graham

On 24/10/2007, Michael Robokoff &lt;mike.robokoff at apioutsourcing.com&gt; wrote:
&gt;<i> # ipcs
</I>&gt;<i> IPC status from &lt;running system&gt; as of Wed Oct 24 06:25:17 CDT 2007
</I>&gt;<i> T         ID      KEY        MODE        OWNER    GROUP
</I>&gt;<i> Message Queues:
</I>&gt;<i> Shared Memory:
</I>&gt;<i> Semaphores:
</I>&gt;<i> s          2   0          --ra-------      api    other
</I>&gt;<i>
</I>&gt;<i> Not sure how to read that.
</I>&gt;<i>
</I>&gt;<i> If the problem is the semaphores, Shouldn't I be able to use the following
</I>&gt;<i> set semsys:seminfo_semmni=2048
</I>&gt;<i> set semsys:seminfo_semmns=2048
</I>&gt;<i> set semsys:seminfo_semmnu=1024
</I>&gt;<i> set semsys:seminfo_semmsl=300
</I>&gt;<i> set semsys:seminfo_semopm=128
</I>&gt;<i> set semsys:seminfo_semume=64
</I>&gt;<i>
</I>&gt;<i> to make more semaphores available?
</I>&gt;<i>
</I>&gt;<i> I tried that but it didn't change anything, do you think that was not
</I>&gt;<i> enough?
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> --Mike
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> -----Original Message-----
</I>&gt;<i> From: Graham Dumpleton [mailto:graham.dumpleton at gmail.com]
</I>&gt;<i> Sent: Tuesday, October 23, 2007 7:08 PM
</I>&gt;<i> To: Michael Robokoff
</I>&gt;<i> Cc: mod_python
</I>&gt;<i> Subject: Re: [mod_python] ValueError: Failed to acquire global mutex lock
</I>&gt;<i>
</I>&gt;<i> If you run 'ipcs' what is the output? Something must be using all the
</I>&gt;<i> semaphores, can't be anything else.
</I>&gt;<i>
</I>&gt;<i> Graham
</I>&gt;<i>
</I>&gt;<i> On 24/10/2007, Michael Robokoff &lt;mike.robokoff at apioutsourcing.com&gt; wrote:
</I>&gt;<i> &gt; Ok the directive did take effect as the log entry below shows:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; [Tue Oct 23 07:20:32 2007] [notice] mod_python: Creating 4 session mutexes
</I>&gt;<i> &gt; based on 6 max processes and 25 max threads.
</I>&gt;<i> &gt; [Tue Oct 23 07:20:32 2007] [notice] mod_python: using mutex_directory /tmp
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Still see this however:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; ValueError: Failed to acquire global mutex lock
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I will try recompiling with the option you mentioned and see what happens.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; --Mike
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; -----Original Message-----
</I>&gt;<i> &gt; From: Graham Dumpleton [mailto:graham.dumpleton at gmail.com]
</I>&gt;<i> &gt; Sent: Tuesday, October 23, 2007 6:40 AM
</I>&gt;<i> &gt; To: Michael Robokoff
</I>&gt;<i> &gt; Cc: mod_python
</I>&gt;<i> &gt; Subject: Re: [mod_python] ValueError: Failed to acquire global mutex lock
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; On 23/10/2007, Michael Robokoff &lt;mike.robokoff at apioutsourcing.com&gt; wrote:
</I>&gt;<i> &gt; &gt; [Thu Oct 18 07:37:38 2007] [notice] mod_python: Creating 8 session
</I>&gt;<i> mutexes
</I>&gt;<i> &gt; &gt; based on 6 max processes and 25 max threads.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; BTW, what did you end up setting mod_python.mutex_locks to? If you use
</I>&gt;<i> &gt; 4 like I said, then it can't have been in correct part of Apache
</I>&gt;<i> &gt; configuration, outside of all VirtualHost, as error log still shows '8
</I>&gt;<i> &gt; session mutexes'.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; if you can't get this to work, you might rebuild mod_python and
</I>&gt;<i> &gt; specific --with-max-locks=4 option to configure to force lower value
</I>&gt;<i> &gt; to be compiled in.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Graham
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: <A HREF="http://mm_cfg_has_not_been_edited_to_set_host_domains/pipermail/mod_python/attachments/20080806/b9d0d366/attachment.html">http://mm_cfg_has_not_been_edited_to_set_host_domains/pipermail/mod_python/attachments/20080806/b9d0d366/attachment.html</A>
</PRE>





<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="025520.html">[mod_python] PyODBC makes me crazy... Is mxODBC working good?
</A></li>
	<LI>Next message: <A HREF="025523.html">[mod_python] ValueError: Failed to acquire global mutex lock
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#25521">[ date ]</a>
              <a href="thread.html#25521">[ thread ]</a>
              <a href="subject.html#25521">[ subject ]</a>
              <a href="author.html#25521">[ author ]</a>
         </LI>
       </UL>

</td>
<td align="right" valign="top">
<script type="text/javascript"><!--
google_ad_client = "pub-9718360309690383";
google_ad_width = 120;
google_ad_height = 600;
google_ad_format = "120x600_as";
google_color_border = "CCCCCC";
google_color_bg = "FFFFFF";
google_color_link = "000000";
google_color_url = "666666";
google_color_text = "333333";
//--></script>
<script type="text/javascript"
  src="DISABLEhttp://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>
</td>
</table>

<hr>
<a href="http://mailman.modpython.org/mailman/listinfo/mod_python">More information about the Mod_python
mailing list</a><br>
</body></html>
